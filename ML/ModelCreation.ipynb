{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "from model_selection import load_dataset, df_train_test_split\n",
    "from settings import BASE_DIR\n",
    "import Preprocess as ps\n",
    "from nltk.stem import SnowballStemmer\n",
    "import TFIDF_Models as cnb\n",
    "import scipy.stats.distributions as dists\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# explicit negations\n",
    "negations = {\"isn't\":\"is not\", \"aren't\":\"are not\", \"wasn't\":\"was not\", \"weren't\":\"were not\",\n",
    "            \"haven't\":\"have not\",\"hasn't\":\"has not\",\"hadn't\":\"had not\",\"won't\":\"will not\",\n",
    "            \"wouldn't\":\"would not\", \"don't\":\"do not\", \"doesn't\":\"does not\",\"didn't\":\"did not\",\n",
    "            \"can't\":\"can not\",\"couldn't\":\"could not\",\"shouldn't\":\"should not\",\"mightn't\":\"might not\",\n",
    "            \"mustn't\":\"must not\"}\n",
    "\n",
    "# convert twitter emojis in twitch style emojis\n",
    "emojis = {':)': 'smile', ':-)': 'smile', ';d': 'wink', ':-E': 'vampire', ':(': 'sad',\n",
    "      ':-(': 'sad', ':-<': 'sad', ':P': 'raspberry', ':O': 'surprised',\n",
    "      ':-@': 'shocked', ':@': 'shocked',':-$': 'confused',\n",
    "      ':#': 'mute', ':X': 'mute', ':^)': 'smile', ':-&': 'confused', '$_$': 'greedy',\n",
    "      '@@': 'eyeroll', ':-!': 'confused', ':-D': 'smile', ':-0': 'yell', 'O.o': 'confused',\n",
    "      '<(-_-)>': 'robot', 'd[-_-]b': 'dj', \":'-)\": 'sadsmile', ';)': 'wink',\n",
    "      ';-)': 'wink', 'O:-)': 'angel','O*-)': 'angel','(:-D': 'gossip', '=^.^=': 'cat'}\n",
    "\n",
    "regex_subs = {\n",
    "                r\"https?://[^s]+\" : \"URL\", # replace any url with URL\n",
    "                \"www.[^ ]+\" : \"URL\", # replace any url with URL\n",
    "                r\"@[^\\s]+\" : \"USR\", # replace any user tag with USR (the tag system is the same also in twitch)\n",
    "                r\"(.)\\1\\1+\" : r\"\\1\\1\", # replace 3 consecutive chars with 2\n",
    "                r\"[\\s]+\" : \" \", # remove consec spaces\n",
    "                \"#[a-z0-9]*\" : \"\" #remove hashtags, they are not used in twitch chats\n",
    "             }\n",
    "\n",
    "sbStem = SnowballStemmer(\"english\", True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading dataset...\n",
      "...dataset loaded\n"
     ]
    }
   ],
   "source": [
    "path = \"{BaseDir}/Advanced_Machine_Learning_Project/data/dataset.csv\".format(BaseDir=BASE_DIR)\n",
    "columns = [\"sentiment\", \"ids\", \"date\", \"flag\", \"user\", \"text\"]\n",
    "final_columns = [\"text\", \"sentiment\"]\n",
    "df = load_dataset(path, columns, final_columns)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting preprocessing...\n",
      "...preprocessing completed\n",
      "starting splitting dataset...\n",
      "...dataset splitted\n"
     ]
    }
   ],
   "source": [
    "preprocess = ps.Preprocess(negations, emojis, regex_subs, sbStem)\n",
    "df = preprocess.df_pre_process(df, \"text\", \"sentiment\")\n",
    "X_train, X_test, Y_train, Y_test = df_train_test_split(df, \"text\", \"sentiment\",test_size=0.05)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting vectorizing words...\n",
      "...words vectorized\n"
     ]
    }
   ],
   "source": [
    "a = RandomizedSearchCV(estimator=Pipeline(steps=[('model',\n",
    "                                              W2VDecisionTreeClassifier())]),\n",
    "                   n_iter=1, n_jobs=1,\n",
    "                   param_distributions=[{'model': [W2VDecisionTreeClassifier()],\n",
    "                                         'model__ccp_alpha': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f28494cdc70>,\n",
    "                                         'model__criterion': ['gini',\n",
    "                                                              'entropy'],\n",
    "                                         'model__epochs': <scipy.stats._distn_infrastructure.rv_frozen ob...\n",
    "                                         'model__max_iter': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f2849666580>,\n",
    "                                         'model__ngram_range': [(1, 2)],\n",
    "                                         'model__penalty': ['l1', 'l2',\n",
    "                                                            'elasticnet',\n",
    "                                                            'none'],\n",
    "                                         'model__solver': ['saga'],\n",
    "                                         'model__tfidf_max_features': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f2849a06e80>,\n",
    "                                         'model__tol': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f2849a06fa0>}],\n",
    "                   return_train_score=True)\n",
    "params_grid =[dict(model = [cnb.TFIDFLogisticRegression()],\n",
    "              model__tfidf_max_features=dists.randint(1, 50000000),\n",
    "              model__ngram_range=[(1, 2)],\n",
    "              model__penalty=['l1', 'l2', 'elasticnet', 'none'],\n",
    "              model__tol=dists.uniform(0.00001, 0.001),\n",
    "              model__C=dists.uniform(0.1, 2.0),\n",
    "              model__fit_intercept=[True, False],\n",
    "              model__solver=['saga'],\n",
    "              model__max_iter=dists.randint(100, 1000+1),\n",
    "              model__l1_ratio = dists.uniform(0.0,1.0))]\n",
    "#\n",
    "# apply_random_search(pip, params_grid, X_train, Y_train)\n",
    "\n",
    "LogReg = cnb.TFIDFLogisticRegression()\n",
    "model = LogReg.fit(X_train, Y_train)\n",
    "\n",
    "# model = search['params'][0]\n",
    "# model['model']=str(model['model'])\n",
    "# model['model'] = model['model'][:model['model'].find('(')]\n",
    "# df = {'model' : [model['model']],\n",
    "#       'mean_fit_time' : [search['mean_fit_time'][0]],\n",
    "#       'mean_score_time': [search['mean_score_time'][0]],\n",
    "#       'mean_train_score' : [search['mean_train_score'][0]],\n",
    "#       'mean_test_score' : [search['mean_test_score'][0]]}\n",
    "# results = results.append(pd.DataFrame(df))\n",
    "# print(results)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting vectorizing words...\n",
      "...words vectorized\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "0.6760375"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(Y_test, prediction)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                      text  sentiment\n0        usr url a bummer. you shoulda got david carr o...          0\n1        is upset that he can not updat his facebook by...          0\n2        usr i dive mani time for the ball. manag to sa...          0\n3           my whole bodi feel itchi and like its on fire           0\n4        usr no, it's not behav at all. i'm mad. why am...          0\n...                                                    ...        ...\n1599995  just woke up. having no school is the best fee...          1\n1599996  thewdb.com - very cool to hear old walt interv...          1\n1599997  are you readi for your mojo makeover? ask me f...          1\n1599998  happi 38th birthday to my boo of all time!! tu...          1\n1599999                                 happi usr usr usr           1\n\n[1600000 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>usr url a bummer. you shoulda got david carr o...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>is upset that he can not updat his facebook by...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>usr i dive mani time for the ball. manag to sa...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>my whole bodi feel itchi and like its on fire</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>usr no, it's not behav at all. i'm mad. why am...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1599995</th>\n      <td>just woke up. having no school is the best fee...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1599996</th>\n      <td>thewdb.com - very cool to hear old walt interv...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1599997</th>\n      <td>are you readi for your mojo makeover? ask me f...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1599998</th>\n      <td>happi 38th birthday to my boo of all time!! tu...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1599999</th>\n      <td>happi usr usr usr</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>1600000 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "980580                     had garlic bread after long time \n718900            at a famili grad party. so. many. drinks. \n1161001    do not forget to watch the mtv movi awards! ne...\n1116629    usr hahaha no its not a bad thing! i just had ...\n656884     went to the dentist over 2 hour ago and i can ...\n                                 ...                        \n1323144    usr we do not have a booth presence, but some ...\n413519                usr ..and i only just got the old one \n1023844    : think bout the lost -- and the cross &amp; p...\n1081151    usr the door is wide open for you!! all day ev...\n274864                           usr i think about it too.. \nName: text, Length: 80000, dtype: object"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0, 0, 1, ..., 1, 1, 0])"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}