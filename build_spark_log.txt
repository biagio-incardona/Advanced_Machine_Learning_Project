Sending build context to Docker daemon  290.2MB
Step 1/20 : FROM openjdk:8-jre
 ---> 7b87e4358a6f
Step 2/20 : ENV PATH $SPARK_DIR/bin:$PATH
 ---> Using cache
 ---> 075863e854d2
Step 3/20 : ENV SPARK_VERSION=2.4.8
 ---> Using cache
 ---> e603efeefd51
Step 4/20 : ENV SPARK_DIR=/opt/spark
 ---> Using cache
 ---> 62e6cad07b47
Step 5/20 : ENV PATH $SPARK_DIR/bin:$PATH
 ---> Using cache
 ---> 194889054b6c
Step 6/20 : ENV PYSPARK_PYTHON=python3.6
 ---> Using cache
 ---> 023ac4a4c48d
Step 7/20 : ADD setup/spark-${SPARK_VERSION}-bin-hadoop2.7.tgz /opt
 ---> Using cache
 ---> 495de0e719f3
Step 8/20 : RUN apt-get update && apt-get -y install bash
 ---> Using cache
 ---> ff6c5c5e8137
Step 9/20 : RUN apt -y install build-essential zlib1g-dev libncurses5-dev libgdbm-dev libnss3-dev libssl-dev libsqlite3-dev libreadline-dev libffi-dev wget libbz2-dev
 ---> Using cache
 ---> 16f775de451c
Step 10/20 : RUN wget https://www.python.org/ftp/python/3.6.9/Python-3.6.9.tgz && 	tar xzf Python-3.6.9.tgz && 	cd Python-3.6.9 && 	./configure && 	make altinstall
 ---> Using cache
 ---> 716c4a2cbe65
Step 11/20 : RUN python3.6 -V
 ---> Using cache
 ---> cda47d6c6395
Step 12/20 : COPY get-pip.py .
 ---> Using cache
 ---> 97a65f035ef6
Step 13/20 : RUN python3.6 get-pip.py
 ---> Using cache
 ---> 7748b46d45da
Step 14/20 : RUN python3.6 -m pip install pyspark==3.2.1 elasticsearch==7.7.0 kafka-python==2.0.2 numpy==1.19.5 scikit-learn==0.24.0 nltk==3.6.7 pandas==1.1.5
 ---> Using cache
 ---> 9649cbb5ba85
Step 15/20 : RUN ln -s /opt/spark-${SPARK_VERSION}-bin-hadoop2.7 ${SPARK_DIR}
 ---> Using cache
 ---> 9f3bdae8224d
Step 16/20 : ADD python/*  /opt/advm/
 ---> ba92af31a6a9
Step 17/20 : RUN unzip ./opt/advm/TFIDF_logisticRegression.zip -d ./opt/advm
 ---> Running in f3ec1170b621
Archive:  ./opt/advm/TFIDF_logisticRegression.zip
  inflating: ./opt/advm/TFIDF_logisticRegression.pkl  
Removing intermediate container f3ec1170b621
 ---> 116c9954d097
Step 18/20 : ADD spark-manager.sh $SPARK_DIR/bin/spark-manager
 ---> d277770a67a2
Step 19/20 : WORKDIR ${SPARK_DIR}
 ---> Running in 40e99a90154f
Removing intermediate container 40e99a90154f
 ---> 398ec4a3f2f6
Step 20/20 : ENTRYPOINT [ "bin/spark-manager" ]
 ---> Running in 59204e5d1260
Removing intermediate container 59204e5d1260
 ---> 631e1bcd43a5
Successfully built 631e1bcd43a5
Successfully tagged advm:spark
