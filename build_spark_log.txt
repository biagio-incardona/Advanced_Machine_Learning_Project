Sending build context to Docker daemon  290.2MB
Step 1/20 : FROM openjdk:8-jre
 ---> 7b87e4358a6f
Step 2/20 : ENV PATH $SPARK_DIR/bin:$PATH
 ---> Using cache
 ---> 075863e854d2
Step 3/20 : ENV SPARK_VERSION=2.4.8
 ---> Using cache
 ---> e603efeefd51
Step 4/20 : ENV SPARK_DIR=/opt/spark
 ---> Using cache
 ---> 62e6cad07b47
Step 5/20 : ENV PATH $SPARK_DIR/bin:$PATH
 ---> Using cache
 ---> 194889054b6c
Step 6/20 : ENV PYSPARK_PYTHON=python3.6
 ---> Using cache
 ---> 023ac4a4c48d
Step 7/20 : ADD setup/spark-${SPARK_VERSION}-bin-hadoop2.7.tgz /opt
 ---> Using cache
 ---> 495de0e719f3
Step 8/20 : RUN apt-get update && apt-get -y install bash
 ---> Using cache
 ---> ff6c5c5e8137
Step 9/20 : RUN apt -y install build-essential zlib1g-dev libncurses5-dev libgdbm-dev libnss3-dev libssl-dev libsqlite3-dev libreadline-dev libffi-dev wget libbz2-dev
 ---> Using cache
 ---> 16f775de451c
Step 10/20 : RUN wget https://www.python.org/ftp/python/3.6.9/Python-3.6.9.tgz && 	tar xzf Python-3.6.9.tgz && 	cd Python-3.6.9 && 	./configure && 	make altinstall
 ---> Using cache
 ---> 716c4a2cbe65
Step 11/20 : RUN python3.6 -V
 ---> Using cache
 ---> cda47d6c6395
Step 12/20 : COPY get-pip.py .
 ---> Using cache
 ---> 97a65f035ef6
Step 13/20 : RUN python3.6 get-pip.py
 ---> Using cache
 ---> 7748b46d45da
Step 14/20 : RUN python3.6 -m pip install pyspark==3.2.1 elasticsearch==7.7.0 kafka-python==2.0.2 numpy==1.19.5 scikit-learn==0.24.0 nltk==3.6.7 pandas==1.1.5
 ---> Using cache
 ---> 9649cbb5ba85
Step 15/20 : RUN ln -s /opt/spark-${SPARK_VERSION}-bin-hadoop2.7 ${SPARK_DIR}
 ---> Using cache
 ---> 9f3bdae8224d
Step 16/20 : ADD python/*  /opt/advm/
 ---> 6209cdf56d1b
Step 17/20 : RUN unzip ./opt/advm/TFIDF_logisticRegression.zip -d ./opt/advm
 ---> Running in 545aa17b11b6
Archive:  ./opt/advm/TFIDF_logisticRegression.zip
  inflating: ./opt/advm/TFIDF_logisticRegression.pkl  
Removing intermediate container 545aa17b11b6
 ---> 0d0fce3958cd
Step 18/20 : ADD spark-manager.sh $SPARK_DIR/bin/spark-manager
 ---> f11f741ebb32
Step 19/20 : WORKDIR ${SPARK_DIR}
 ---> Running in 0a25c9d1ad5c
Removing intermediate container 0a25c9d1ad5c
 ---> ac8673eb3592
Step 20/20 : ENTRYPOINT [ "bin/spark-manager" ]
 ---> Running in 7ed358726cd1
Removing intermediate container 7ed358726cd1
 ---> 6931fbe04dee
Successfully built 6931fbe04dee
Successfully tagged advm:spark
