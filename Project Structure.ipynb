{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Live Stream Chat Analysis \n",
    "\n",
    "#### Authors\n",
    "\n",
    "Anahita Esfandiaryfard, Aarcha Jayachandran Nair Prasanna Kumari, Biagio Incardona\n",
    "\n",
    "## Disclaimer\n",
    "\n",
    "We know that for the scope of this project some of the tools can be avoided (like kafka and spark), but since they are higly demanded by many companies for data science jobs we thought it could be nice to have a bit of experience with those software too, that's why we decided to build a real world application rather than doing a \"normal\" academic project.\n",
    "\n",
    "## What is it?\n",
    "\n",
    "Stream Live Stream Chat Anaysis is an university project made for the **ADVANCED MACHINE LEARNING** class. The project consists of a real-time analysis of the viewer's interactions of a live stream on Twitch.\n",
    "\n",
    "## For Who?\n",
    "\n",
    "The project is aimed to those streamers who want to monitor how the viewers are interacting with the stream without having to look at the chat.\n",
    "\n",
    "The project can also be used by potential investors to identify whether the streamer has a good fanbase or not.\n",
    "\n",
    "## Goal\n",
    "\n",
    "The main goal is to have a simply interface (a dashboard) to analyze the viewers behavior since the chats in a live stream can be really messed up.\n",
    "\n",
    "A dashboard will then be provided containing real time measures of some specific KPIs (like the sentyment per message, the average sentyment of the messages, the engagement of the viewers and so on...)\n",
    "\n",
    "## Structure\n",
    "\n",
    "<img src=\"https://github.com/biagio-incardona/Advanced_Machine_Learning_Project/blob/master/ML/images/schema.jpg">\n",
    "\n",
    "The project can be split into 5 different phases:\n",
    "\n",
    "    1. Ingestion\n",
    "    2. Streaming\n",
    "    3. Processing\n",
    "    4. Indexing\n",
    "    5. Visualization\n",
    "\n",
    "### 1. Ingestion\n",
    "\n",
    "The ingestion phase consists in the collection of the data from external sources, in this case our source will be the Twitch platform.\n",
    "\n",
    "This will be achieved by collecting data in real time using Twitch APIs and the data will be ingested using **Logstash** (so that the project can be easily extended with other sources).\n",
    "\n",
    "#### Logstash\n",
    "\n",
    "Logstash is a tool for collecting, processing, and forwarding log events and messages. The collection is done through configurable input plug-ins. Once an input plug-in has collected the data, it can be processed by any number of filters that modify and annotate the event data. Finally Logstash routes events to output plugins which can forward events to a variety of external programs including Elasticsearch, local files, Kafka, and others.\n",
    "\n",
    "For our purpose, Logstash will collect the data from the scraper in JSON format over a TCP connection and then forward it to Kafka using the \"data\" topic.\n",
    "\n",
    "### 2. Streaming\n",
    "\n",
    "To carry out the data streaming Apache Kafka will be used.\n",
    "\n",
    "#### Apache Kafka\n",
    "\n",
    "Apache Kafka is a distributed data streaming platform that allows you to publish, subscribe, archive, and process streams of records in real-time. It is designed to manage data streams from multiple sources by distributing them to multiple consumers. In short, it allows you to move large amounts of data from one point to another at the same time.\n",
    "\n",
    "### 3. Processing\n",
    "\n",
    "Once we have collected the data through Kafka we want to manipulate and obtain additional information from this data.\n",
    "\n",
    "For this purpose, we will rely on Apache Spark.\n",
    "\n",
    "#### Apache Spark\n",
    "\n",
    "Apache Spark is a distributed computing framework that runs 100 times faster than its main competitor (MapReduce).\n",
    "\n",
    "Spark is optimized for machine learning algorithm.\n",
    "\n",
    "For the creation and manipulation of DataFrame on the fly we will use PySpark, the API provided by Spark to interface with it via Python.\n",
    "\n",
    "#### Machine Learning\n",
    "\n",
    "By relying on spark we can apply ML algorithms very quickly.\n",
    "\n",
    "We will apply only one ML algorithm: A sentyment analysis algorithm.\n",
    "\n",
    "We will train this algorithm using the [Sentiment140](https://www.kaggle.com/kazanova/sentiment140) Dataset. The ML algorithms we will try to fit have to be decided.\n",
    "\n",
    "### 4. Indexing\n",
    "\n",
    "Our data will be indexed in order to reduce research costs. For this purpose, we will make use of ElasticSearch.\n",
    "\n",
    "#### ElasticSearch\n",
    "\n",
    "ElasticSearch is a search engine based on Lucene, the fastest Open Source data retrieval API used for the development of search engines.\n",
    "\n",
    "All the functionalities are natively exposed through the RESTful interface, while the information is managed as JSON documents.\n",
    "\n",
    "In the project, we will use only one index: \"data\" (but different indexes can be added if we want to add multiple sources without affecting the computational cost)\n",
    "\n",
    "### 5. Visualization\n",
    "\n",
    "To visualize the data we will use Kibana\n",
    "\n",
    "#### Kibana\n",
    "\n",
    "Kibana is an open-source data visualization dashboard for Elasticsearch. sending the functionality of viewing indexed content on Elasticsearch. Users can create bar, line, and pie charts and maps over large volumes of data.\n",
    "\n",
    "## Implementation\n",
    "\n",
    "Considering that installing tons of software just to evaluate a project can be annoying we will virtualize everything using docker (so that you just need docker to evaluate and test the project).\n",
    "\n",
    "Considering also that all the software are made to be distributed we will build a separate container for each phase and then build a private docker network to simulate a distributed enviroment (all the containers will communicate over the private network using the *TCP* protocol).\n",
    "\n",
    "You will also be provided of three bash files to build the containers, executed them in the correct order and with the correct parameters and stop them in the correct way.\n",
    "\n",
    "##"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
